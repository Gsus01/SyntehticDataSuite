# Modelo HMM (Hidden Markov Model) - Gu√≠a de Uso

## Descripci√≥n

El **Hidden Markov Model (HMM)** es un modelo estad√≠stico que supone que el sistema que se est√° modelando es un proceso de Markov con estados no observados (ocultos). Es especialmente √∫til para:

- **Series temporales** con reg√≠menes o estados subyacentes
- **Datos secuenciales** donde el orden importa
- **Detecci√≥n de patrones** en comportamientos cambiantes
- **Segmentaci√≥n** de secuencias en diferentes estados

## Caracter√≠sticas del HMM en SyntheticDataSuite

### Funcionalidades principales:
- ‚úÖ Entrenamiento con datos multivariados
- ‚úÖ Generaci√≥n de datos sint√©ticos secuenciales
- ‚úÖ Predicci√≥n de estados ocultos
- ‚úÖ Manejo de columnas de secuencia temporal
- ‚úÖ Configuraci√≥n flexible de hiperpar√°metros
- ‚úÖ Guardado y carga de modelos entrenados

### Funcionalidades adicionales:
- **Estados ocultos incluidos**: Los datos generados incluyen la secuencia de estados ocultos
- **√çndice secuencial**: Se mantiene el orden temporal en los datos sint√©ticos
- **Metadatos preservados**: Informaci√≥n sobre columnas y configuraci√≥n se guarda con el modelo

## Configuraci√≥n

### Par√°metros principales:

```python
config = {
    "model_type": "hmm",
    "hmm_columns_to_use": ["feature1", "feature2"],  # OPCIONAL: si no se especifica, usa todas las columnas num√©ricas
    "hmm_n_states": 3,                              # N√∫mero de estados ocultos
    "hmm_covariance_type": "diag",                  # Tipo de covarianza
    "hmm_n_iter": 100,                              # M√°ximo de iteraciones
    "hmm_sequence_column": "timestamp",             # OPCIONAL: para ordenar datos
    "hmm_random_state": 42,                         # Para reproducibilidad
    "hmm_tol": 1e-2,                                # Tolerancia de convergencia
    "hmm_algorithm": "viterbi",                     # Algoritmo de decodificaci√≥n
}
```

### Tipos de covarianza explicados:

| Tipo | Descripci√≥n | Cu√°ndo usar |
|------|-------------|-------------|
| `"diag"` | Variables independientes | **Por defecto** - M√°s r√°pido, buena opci√≥n inicial |
| `"full"` | Variables correlacionadas | Cuando las features est√°n relacionadas |
| `"tied"` | Misma variaci√≥n en todos los estados | Estados con variabilidad similar |
| `"spherical"` | Variaci√≥n uniforme | Variables con escalas similares (restrictivo) |

### Auto-selecci√≥n de columnas:

Si no especificas `hmm_columns_to_use`, el modelo autom√°ticamente:

1. **Selecciona todas las columnas num√©ricas** del DataFrame
2. **Excluye la columna de secuencia** (si est√° especificada en `hmm_sequence_column`)
3. **Excluye columnas comunes que no son features**: como 'id', 'index', 'true_state', 'label', 'target'

```python
# Configuraci√≥n autom√°tica - usa todas las columnas num√©ricas
config_auto = {
    "model_type": "hmm",
    # hmm_columns_to_use no especificado = auto-selecci√≥n
    "hmm_sequence_column": "timestamp",  # Se excluir√° autom√°ticamente
    "hmm_n_states": 3,
}

# Equivale a especificar manualmente todas las columnas num√©ricas
# (excluyendo 'timestamp' y columnas como 'id', 'true_state', etc.)
```

## Ejemplos de uso

### 1. Caso b√°sico - Series temporales simples

```python
from src.flows.training import training_flow

# Configuraci√≥n simple con auto-selecci√≥n de columnas
config = {
    "model_type": "hmm",
    # hmm_columns_to_use no especificado = usa todas las columnas num√©ricas autom√°ticamente
    "hmm_sequence_column": "timestamp",  # Columna temporal (se excluir√° de features)
    "hmm_n_states": 3,  # Ej: fr√≠o, templado, calor
    "hmm_covariance_type": "diag",
    "hmm_n_iter": 100,
}

# Entrenar modelo - usar√° autom√°ticamente columnas como 'temperature', 'humidity', etc.
model_path = training_flow(
    data_path="data/weather_data.csv",  # Debe tener columnas num√©ricas
    model_name="weather_hmm",
    config=config
)
```

### 2. Caso avanzado - Datos financieros

```python
# Configuraci√≥n para datos financieros (bull/bear markets)
financial_config = {
    "model_type": "hmm",
    "hmm_columns_to_use": ["returns", "volatility", "volume"],
    "hmm_sequence_column": "date",  # Ordenar por fecha
    "hmm_n_states": 2,  # Bull vs Bear market
    "hmm_covariance_type": "full",  # Variables correlacionadas
    "hmm_n_iter": 200,
    "hmm_random_state": 42,
}

model_path = training_flow(
    data_path="data/stock_data.csv",
    model_name="market_regime_hmm",
    config=financial_config
)
```

### 3. Generaci√≥n de datos sint√©ticos

```python
from src.models.hmm_model import HMMWrapper

# Cargar modelo entrenado
hmm_model = HMMWrapper(
    model_name="weather_hmm",
    model_path="./model_registry/weather_hmm/model.pkl",
    config={}  # Se carga del archivo
)
hmm_model.load_model()

# Generar 1000 muestras sint√©ticas
synthetic_data = hmm_model.sample(n_samples=1000)

print(synthetic_data.head())
# Salida incluye:
# - Las columnas originales (temperature, humidity)
# - hidden_state: estado oculto en cada momento
# - sequence_index: √≠ndice temporal
```

### 4. Predicci√≥n de estados ocultos

```python
# Predecir estados para nuevos datos
import pandas as pd

new_data = pd.DataFrame({
    'temperature': [25.1, 30.5, 15.2],
    'humidity': [60.2, 45.8, 80.1]
})

hidden_states = hmm_model.predict_hidden_states(new_data)
print(f"Estados predichos: {hidden_states}")
# Salida: [1 2 0] (ejemplo)
```

## Casos de uso recomendados

### üåü Ideal para:
- **Series temporales de r√©gimen**: Clima, mercados financieros, comportamiento de usuarios
- **Datos secuenciales**: Logs de eventos, trayectorias, procesos industriales
- **Segmentaci√≥n temporal**: Identificar per√≠odos con comportamientos distintos
- **An√°lisis de transiciones**: Estudiar cambios entre estados

### ‚ö†Ô∏è Limitaciones:
- Supone **dependencia de primer orden** (estado actual solo depende del anterior)
- **No adecuado** para dependencias a largo plazo sin estados intermedios
- Requiere que el **orden de los datos sea significativo**

## Comparaci√≥n con otros modelos

| Caracter√≠stica | HMM | GMM | Ventaja HMM |
|----------------|-----|-----|-------------|
| **Orden temporal** | ‚úÖ S√≠ | ‚ùå No | Preserva secuencias |
| **Estados ocultos** | ‚úÖ S√≠ | ‚ùå No | Interpretabilidad |
| **Transiciones** | ‚úÖ Modeladas | ‚ùå No | Din√°micas temporales |
| **Complejidad** | Media | Baja | Balance flexibilidad/simplicidad |

## Troubleshooting

### Problemas comunes:

1. **Modelo no converge**:
   - Aumentar `hmm_n_iter`
   - Reducir `hmm_tol`
   - Cambiar `hmm_covariance_type`

2. **Estados poco interpretables**:
   - Reducir `hmm_n_states`
   - Verificar calidad de los datos
   - Probar diferentes `covariance_type`

3. **Performance lenta**:
   - Usar `"diag"` en lugar de `"full"`
   - Reducir `hmm_n_states`
   - Reducir `hmm_n_iter`

### Validaci√≥n del modelo:

```python
# Revisar convergencia
print(f"¬øConvergi√≥? {hmm_model.model.monitor_.converged}")

# Log-likelihood del modelo
score = hmm_model.model.score(training_data)
print(f"Log-likelihood: {score}")
```

## Referencias

- [hmmlearn Documentation](https://hmmlearn.readthedocs.io/)
- [Hidden Markov Models Tutorial](https://web.stanford.edu/~jurafsky/slp3/A.pdf)
- [Rabiner, L.R. "A tutorial on hidden Markov models"](https://ieeexplore.ieee.org/document/18626) 